{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import *\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU   \n",
    "from keras import optimizers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import sys\n",
    "# sys.stdout = open('log.txt','wt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop out with global pool 500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'E:\\\\aptos\\\\labelsbase15.json'\n",
    "# path = 'E:\\\\aptos\\\\labelsnovel15.json'\n",
    "# path = 'E:\\\\aptos\\\\labelsval15.json'\n",
    "# path = \"/home/z5163479/code/base15.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "labels = np.array(data['image_labels'])\n",
    "images = np.array(data['image_names'])\n",
    "k = 500\n",
    "print(\"drop out with global pool {}\\n\".format(k))\n",
    "# print(\"normal flaten {}\\n\".format(k))\n",
    "\n",
    "zero_images = images[labels == 0][:k]\n",
    "one_images = images[labels == 1][:k]\n",
    "two_images = images[labels == 2][:k]\n",
    "three_images = images[labels == 3][:k]\n",
    "four_images1 = images[labels == 4][:k]\n",
    "\n",
    "\n",
    "# # print(zero_images.shape)\n",
    "# images_dict = {\n",
    "#     0:zero_images,\n",
    "#     1:one_images,\n",
    "#     2:two_images,\n",
    "#     3:three_images,\n",
    "#     4:four_images\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(four_images))\n",
    "print(len(three_images))\n",
    "print(len(two_images))\n",
    "print(len(one_images))\n",
    "print(len(zero_images1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'E:\\\\aptos\\\\labelsnovel15.json'\n",
    "labels = np.array(data['image_labels'])\n",
    "images = np.array(data['image_names'])\n",
    "k = 106\n",
    "four_images2 = images[labels == 4][:k]\n",
    "len(four_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_images = [y for x in [four_images1, four_images2] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(four_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = {\n",
    "    0:zero_images,\n",
    "#     1:one_images,\n",
    "#     2:two_images,\n",
    "#     3:three_images,\n",
    "    4:four_images\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(images_dict):\n",
    "    data = {\n",
    "        0:[],\n",
    "#         1:[],\n",
    "#         2:[],\n",
    "#         3:[],\n",
    "        4:[]\n",
    "    }\n",
    "    for label, img_paths in images_dict.items():\n",
    "        for img_path in img_paths:\n",
    "            img = image.load_img(img_path, target_size=(587,587))\n",
    "            img = image.img_to_array(img)\n",
    "            data[label].append([img, label])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data(images_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_dict):\n",
    "    trainset = []\n",
    "    valset = []\n",
    "    testset=[]\n",
    "    for label, images in data.items():\n",
    "        random.shuffle(images)\n",
    "        img_train, img_test = train_test_split(images, test_size=0.2)\n",
    "        img_train, img_val = train_test_split(img_train,test_size=0.1)\n",
    "        trainset = trainset + img_train\n",
    "        valset = valset + img_val\n",
    "        testset = testset + img_test\n",
    "    \n",
    "    return trainset, valset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, val_test, img_test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "1800\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(val_test))\n",
    "print(len(img_train))\n",
    "print(len(img_test))\n",
    "val_size = len(val_test)\n",
    "train_size = len(img_train)\n",
    "test_size = len(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
